# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ ‚Ññ1

##  –ó–∞–¥–∞–Ω–∏–µ 1
```python
name = input('–í–≤–µ–¥–∏—Ç–µ –≤–∞—à–µ –∏–º—è: ')
age = int(input('–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –≤–æ–∑—Ä–∞—Å—Ç: '))
print(f'–ü—Ä–∏–≤–µ—Ç, {name}! –ß–µ—Ä–µ–∑ –≥–æ–¥ —Ç–µ–±–µ –±—É–¥–µ—Ç {age+1}.')
```

![–†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–¥–∞–Ω–∏—è 1](/images/image-0.png)

##  –ó–∞–¥–∞–Ω–∏–µ 2
```python
first_value = str(input('–í–≤–µ–¥–∏—Ç–µ –ø—Ä–µ–≤–æ–µ —á–∏—Å–ª–æ: '))
second_value = str(input('–í–≤–µ–¥–∏—Ç–µ –≤—Ç–æ—Ä–æ–µ —á–∏—Å–ª–æ: '))
if ',' in first_value or second_value:
    first_value = first_value.replace(',', '.')
    second_value = second_value.replace(',', '.')
a = float(first_value)
b = float(second_value)
avg = round((a + b)/2,2)
sum = a + b
print(sum, avg)
```
![–†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–¥–∞–Ω–∏—è 2](/images/image-1.png)

##  –ó–∞–¥–∞–Ω–∏–µ 3
```python
price = float(input('–ïnter the product price: '))
discount = float(input('–ïnter the discount of the product:' ))
vat = float(input('–ïnter vat of the product:' ))
base = price * (1 - discount/100)
vat_amount = base * (vat/100)
total = base + vat_amount

print(f'Base after discount: {base}')
print(f'Vat: {vat}')
print(f'Final summ: {total}')
```
![–†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–¥–∞–Ω–∏—è 3](/images/image-2.png)

##  –ó–∞–¥–∞–Ω–∏–µ 4
```python
minutes = int(input('–ú–∏–Ω—É—Ç—ã: '))
hour = minutes//60
min = minutes % 60
if min < 10: 
    min = '0' + f'{min}'
print(f'{hour}:{min}')
```
![–†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–¥–∞–Ω–∏—è 4](/images/image-3.png)

##  –ó–∞–¥–∞–Ω–∏–µ 5
```python
name = str(input('–§–ò–û: ')).strip().title()
name = ' '.join(name.split())
initials = name.split()
initials = ''.join(initials[0] for initials in initials)
print(len(f'{name}'), initials)
```
![–†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–¥–∞–Ω–∏—è 5](/images/image-4.png)

##  –ó–∞–¥–∞–Ω–∏–µ 6
```python
n = int(input('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤: '))
online = 0
offline = 0
for _ in range(n):
    data = input().split()
    format = data[-1]
    if format == 'False':
        offline+=1
    else:
        online+= 1
print(f'{online} {offline}')
```
![–†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–¥–∞–Ω–∏—è 6](/images/image-5.png)

##  –ó–∞–¥–∞–Ω–∏–µ 7
```python
a = 'QWERTYUIOPASDFGHJKLZXCVBNM'
b = '012345689'
ch = 'thisisabracadabraHt1eadljjl12ojh.'
word = ''
moves = []
for i in range(len(ch)):
    if ch[i] in a:
        word += ch[i]
        moves.append(i)
        break
for i in range(len(ch)):
    if ch[i] in b:
        word += ch[i+1]
        moves.append(i+1)
        break
for i in range(len(ch)):
    if moves[-1] - moves[-2] == i-moves[-1]:
        word += ch[i]
        moves.append(i)
if word[-1] == '.':
    print(word)
else:
    print('–í –∫–æ–Ω—Ü–µ –¥–æ–∂–Ω–∞ –±—ã—Ç—å —Ç–æ—á–∫–∞!!! ')
```
![–†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–¥–∞–Ω–∏—è 7](/images/image-6.png)

# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ ‚Ññ2

##  –ó–∞–¥–∞–Ω–∏–µ 1.1
```python
from typing import Union, List, Tuple 
def min_max(nums: List[Union[float, int]]) -> Tuple[Union[float, int]]:
    if not nums:
        return ('ValueError')
    return min(nums), max(nums)
print('\n–¢–µ—Å—Ç min_max: ')
print(min_max([3, -1, 5, 5, 0]))
print(min_max([42]))
print(min_max([]))
print(min_max([1.5, 2, 2.0, -3.1]))
```
![–†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–¥–∞–Ω–∏—è 1.1](/images/image-8.png)

##  –ó–∞–¥–∞–Ω–∏–µ 1.2
```python
def unique_sorted(nums: List[float|int]) -> List[float|int]:
    return sorted(set(nums)) #–≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫
print("\n–¢–µ—Å—Ç unique_sorted:")
print(unique_sorted([3, 1, 2, 1, 3]))
print(unique_sorted([]))
print(unique_sorted([-1, -1, 0, 2, 2]))
print(unique_sorted([1.0, 1, 2.5, 2.5, 0]))
![–†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–¥–∞–Ω–∏—è 1.2](/images/image-10.png)
```
##  –ó–∞–¥–∞–Ω–∏–µ 1.3
```python
def flatten(mat: List[List|Tuple]) -> List:
    result = [] 
    for element in mat:
        if not isinstance(element, (list, tuple)): #–ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ç–∏–ø –¥–∞–Ω—ã—Ö
            return ('TypeError')
        result.extend(element)
    return result
print("\n–¢–µ—Å—Ç flatten:")
print(flatten([[1, 2], [3, 4]]))
print(flatten([[1, 2], (3, 4, 5)]))
print(flatten([[1, 2], (3, 4, 5)]))
print(flatten([[1, 2], "ab"]))
```
![–†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–¥–∞–Ω–∏—è 1.3](/images/image-12.png)

##  –ó–∞–¥–∞–Ω–∏–µ 2.1
```python
def transpose(mat: list[list[float | int]]) -> list[list]:
    if len(mat)==0:
        return []
    num_cols = len(mat[0]) #–¥–ª–∏–Ω–∞ —Å—Ç–æ–ª–±–∏–∫–æ–≤
    if any(len(row) != num_cols for row in mat):
        return ('ValueError')
    return [[mat[i][j] for i in range(len(mat))] for j in range(num_cols)]
print('\n–¢–µ—Å—Ç transpose:')
print(transpose([[1, 2, 3]]))
print(transpose([[1], [2], [3]]))
print(transpose([[1, 2], [3, 4]]))
print(transpose([]))
print(transpose([[1, 2], [3]]))
```
![–†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–¥–∞–Ω–∏—è 2.1](/images/image-13.png)

##  –ó–∞–¥–∞–Ω–∏–µ 2.2
```python
def row_sums(mat: list[list[float|int]]) -> list[float]:
    if len(mat) == 0: 
        return []
    num_cols = len(mat[0])
    if any(len(row) != num_cols for row in mat):
        return ('ValueError')
    return[sum(row) for row in mat]
print('\n–¢–µ—Å—Ç row_sums:')
print(row_sums([[1, 2, 3], [4, 5, 6]]))
print(row_sums([[-1, 1], [10, -10]]))
print(row_sums([[0, 0], [0, 0]]))
print(row_sums([[1, 2], [3]]))
```
![–†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–¥–∞–Ω–∏—è 2.2](/images/image-14.png)
##  –ó–∞–¥–∞–Ω–∏–µ 2.3
```python
def col_sums(mat: list(list[float|int])) -> list[float]:
    if len(mat) == 0:
        return []
    num_cols = len(mat[0])
    if any(len(row) != num_cols for row in mat):
        return ('ValueError')
    return[sum(mat[i][j] for i in range(len(mat))) for j in range(num_cols) ]
print('\n–¢–µ—Å—Ç col_sums:')
print(col_sums([[1, 2, 3], [4, 5, 6]]))
print(col_sums([[-1, 1], [10, -10]]))
print(col_sums([[0, 0], [0, 0]]))
print(col_sums([[1, 2], [3]]))
```
![–†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–¥–∞–Ω–∏—è 2.2](/images/image-15.png)

## –ó–∞–¥–∞–Ω–∏–µ 3
```python
# name_input = input('–§–ò–û: ').strip()
# group_input = input('–ì—Ä—É–ø–ø–∞: ').strip()
# gpa_input = float(input('GPA: ').strip())
# student_data = (name_input, group_input, gpa_input)
def format_record(rec: tuple([str, str, float])) -> str:
    if not isinstance(rec, tuple):
        return TypeError("–ê—Ä–≥–∫–º–µ–Ω—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∫–æ—Ä—Ç–µ–∂–µ–º")
    if len(rec) < 3:
        return ValueError("–ö–æ—Ä—Ç–µ–∂ –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å 3 —ç–ª–µ–º–µ–Ω—Ç–∞")
    if not isinstance(rec[2], float):
        return TypeError("3 —ç–ª–µ–º–µ–Ω—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–ª–∞–≤–∞—é—â–∏–º —á–∏—Å–ª–æ–º")
    name, group, gpa = rec
    name_set = ' '.join(name.strip().split()).title()
    parts_name = name_set.split()
    if len(parts_name) < 2:
        raise ValueError('–§–ò–û –¥–æ–∂–µ–Ω –±—ã—Ç—å –¥–ª–∏–Ω–µ–µ –¥–≤—É—Ö —Å–ª–æ–≤')
    surname = parts_name[0]
    initials = [x[0] + '.' for x in parts_name[1:]]
    name_end = f"{surname} {''.join(initials)}"
    group_set= group
    gpa_set = f'{gpa:.2f}'
    return f'{name_end}, –≥—Ä. {group_set}, GPA {gpa_set}'
# result = format_record(student_data)
# print(result)

if __name__ == "__main__":
    # –¢–µ—Å—Ç-–∫–µ–π—Å—ã –∏–∑ –∑–∞–¥–∞–Ω–∏—è
    test_cases = [
        ("–ò–≤–∞–Ω–æ–≤ –ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤–∏—á", "BIVT-25", 4.6),
        ("–ü–µ—Ç—Ä–æ–≤ –ü—ë—Ç—Ä", "IKBO-12", 5.0),
        ("–ü–µ—Ç—Ä–æ–≤ –ü—ë—Ç—Ä –ü–µ—Ç—Ä–æ–≤–∏—á", "IKBO-12"),
        ("  —Å–∏–¥–æ—Ä–æ–≤–∞  –∞–Ω–Ω–∞   —Å–µ—Ä–≥–µ–µ–≤–Ω–∞ ", "ABB-01", 3.999),
    ]
    for test in test_cases:
        print(format_record(test))
```
![–†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–¥–∞–Ω–∏—è 3](/images/image-16.png)

# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ ‚Ññ3

## –ó–∞–¥–∞–Ω–∏–µ 1.1
```python
import re
def normalize(text: str, *, casefold: bool = True, yo2e: bool = True) -> str:
    if not text:
        return []
    if casefold == True:
        text = text.casefold()
    if yo2e == True:
        text = text.replace('—ë', '–µ').replace('–Å', '–ï')
    text = re.sub("[^a-z–∞-—è—ë0-9\s]","", text) # –£–¥–∞–ª–µ–Ω–∏–µ –≤—Å–µ—Ö —Å–∏–º–≤–æ–ª–æ–≤, –∫—Ä–æ–º–µ –±—É–∫–≤, —Ü–∏—Ñ—Ä –∏ –ø—Ä–æ–±–µ–ª–æ–≤
    text = re.sub(r'\s+', ' ', text).strip()
    return text

if __name__ == "__main__":
    test_cases = [
        "–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t",
        "—ë–∂–∏–∫, –Å–ª–∫–∞" ,
        "Hello\r\nWorld",
        "  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  "
    ]
    print('\n–¢–µ—Å—Ç normalize:')
    for test in test_cases:
        print(f"{normalize(test, casefold= True, yo2e = True)}")
```
![–†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–¥–∞–Ω–∏—è 1](/images/image-17.png)

## –ó–∞–¥–∞–Ω–∏–µ 1.2
```python
def tokenize(text:str) -> list[str]:
    if not text:
        return []
    word = r'\b\w+(?:-\w+)*\b' # —á–µ—Ä–µ–∑ —Ä–µ–≥—É–ª—è—Ä–∫—É –∑–∞–¥–∞–µ–º –∫–∞–∫–∏–º –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ª–æ–≤–æ
    tokens = re.findall(word, text)
    return tokens

if __name__ == '__main__':
    test_cases = [
        "–ø—Ä–∏–≤–µ—Ç –º–∏—Ä",
        "hello,world!!!",
        "–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ",
        "2025 –≥–æ–¥",
        "emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ"
    ]
    print("\n–¢–µ—Å—Ç –Ω–∞ tokenize")
    for test in test_cases:
        print(f"{tokenize(test)}")
```
![–†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–¥–∞–Ω–∏—è 1.2](/images/image-18.png)

## –ó–∞–¥–∞–Ω–∏–µ 1.3
```python
def count_freq(tokens: list[str]) -> dict[str, int]:
    dictionary = {}
    for token in tokens:
        dictionary[token] = dictionary.get(token, 0) + 1
    return dictionary

if __name__ == '__main__':
    test_cases = [
        "a","b","a","c","b","a"
        ]
    print("\n–¢–µ—Å—Ç –Ω–∞ count_freq")
    print(count_freq(test_cases))
```
![–†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–¥–∞–Ω–∏—è 1.3](/images/image-19.png)

## –ó–∞–¥–∞–Ω–∏–µ 1.4
```python
def top_n(freq: dict[str, int], n: int = None) -> list[str, int]:
    items = sorted(freq.items(), key= lambda x: (-x[1], x[0]))
    return items[:n]

if __name__ == '__main__':
    test_cases = [
        'aa bb b b d b b d a a'
        ]
    print('\n–¢–µ—Å—Ç –Ω–∞ top_words:')
    for test in test_cases:
        normalized = normalize(test)
        tokens = tokenize(normalized)
        freq = count_freq(tokens)
        top_words = top_n(freq,3)
    print(top_words)
```
![–†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–¥–∞–Ω–∏—è 1.4](/images/image-20.png)

## –ó–∞–¥–∞–Ω–∏–µ 2 

```python 
import sys, os
sys.path.append(os.path.dirname(os.path.dirname(__file__)))
from src.text import normalize, tokenize, count_freq, top_n
TABLE_MODE = True
def print_table(top_items):
    max_len_word = max(len(word) for word, _ in top_items)
    col_1 = "—Å–ª–æ–≤–æ"
    col_2 = "—á–∞—Å—Ç–æ—Ç–∞"
    width = max(max_len_word, len(col_1))

    print('—Å–ª–æ–≤–æ' + ' '* ((width+4)-len(col_1)) + "| —á–∞—Å—Ç–æ—Ç–∞" )
    print("-"*(width+4)*2)

    for word, count in top_items:
        print(f"{word}" + ' ' * ((width+4)-len(word)) + f'| {count}')

def main():
    text = sys.stdin.readline().strip()
    normalized = normalize(text)
    tokens = tokenize(normalized)
    freq = count_freq(tokens)

    total_words = len(tokens)
    unique_words = len(set(tokens))
    top_5 = top_n(freq,5)
    all_words = count_freq(tokens)

    if TABLE_MODE:
        print_table(top_5)
    else:
        print(f"–í—Å–µ–≥–æ —Å–ª–æ–≤: {total_words}")
        print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {unique_words}")
        print("–¢–æ–ø-5:")
        for word, count in top_5:
            print(f"{word}:{count}")
if __name__ == "__main__":
    print(f"–¢–∞–±–ª–∏—á–Ω—ã–π —Ä–µ–∂–∏–º: {'–í–ö–õ' if TABLE_MODE else '–í–´–ö–õ'}")
    main()
```
## –ï—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω —Ä–µ–∂–∏–º –ø–æ–∫–∞–∑–∞–∞ —Ç–∞–±–ª–∏—Ü—ã:
![–†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–¥–∞–Ω–∏—è 1.4](/images/image-21.png)
## –ï—Å–ª–∏ –≤—ã–∫–ª—é—á–µ–Ω —Ä–µ–∂–∏–º –ø–æ–∫–∞–∑–∞–∞ —Ç–∞–±–ª–∏—Ü—ã:
![–†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–¥–∞–Ω–∏—è 1.4](/images/image-22.png)


# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ ‚Ññ4

## –ó–∞–¥–∞–Ω–∏–µ A
```python
from pathlib import Path

def read_text(path: str | Path, encoding: str = "utf-8") -> str:
    """
    –û—Ç–∫—Ä—ã—Ç—å —Ñ–∞–π–ª –Ω–∞ —á—Ç–µ–Ω–∏–µ –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–π –∫–æ–¥–∏—Ä–æ–≤–∫–µ –∏ –≤–µ—Ä–Ω—É—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∫–∞–∫ –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É.
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –æ—à–∏–±–∫–∏: –µ—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω ‚Äî –ø–æ–¥–Ω–∏–º–∞—Ç—å FileNotFoundError (–ø—É—Å—Ç—å –ø–∞–¥–∞–µ—Ç), –µ—Å–ª–∏ –∫–æ–¥–∏—Ä–æ–≤–∫–∞ –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç ‚Äî –ø–æ–¥–Ω–∏–º–∞—Ç—å UnicodeDecodeError (–ø—É—Å—Ç—å –ø–∞–¥–∞–µ—Ç).
    –ù–û: –≤ –¥–æ–∫—Å—Ç—Ä–∏–Ω–≥–µ –æ–ø–∏—à–∏—Ç–µ, –∫–∞–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –º–æ–∂–µ—Ç –≤—ã–±—Ä–∞—Ç—å –¥—Ä—É–≥—É—é –∫–æ–¥–∏—Ä–æ–≤–∫—É (–ø—Ä–∏–º–µ—Ä: encoding="cp1251")."""
    p = Path(path)
    # FileNotFoundError –∏ UnicodeDecodeError –ø—É—Å—Ç—å ¬´–≤—Å–ø–ª—ã–≤–∞—é—Ç¬ª ‚Äî —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ
    try:
        return p.read_text(encoding=encoding) # –°—á–∏—Ç—ã–≤–∞–µ–º —Ç–µ–∫—Å—Ç
    except FileNotFoundError:
        raise FileNotFoundError('–ù–µ—Ç —Ç–∞–∫–æ–≥–æ —Ñ–∞–π–ª–∞')
    except UnicodeDecodeError:
        raise UnicodeDecodeError('–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –∫–æ–¥–∏—Ä–æ–≤–∫–∞')
    
text_1 = read_text(r'C:\Users\hoang\OneDrive\Desktop\laba\python_labs\data\input.txt')
print(text_1)


import csv
from typing import Iterable, Sequence

def write_csv(rows: Iterable[Sequence], path: str | Path, header: tuple[str, ...] | None = None) -> None:
    """–°–æ–∑–¥–∞—Ç—å/–ø–µ—Ä–µ–∑–∞–ø–∏—Å–∞—Ç—å CSV —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º ,.
    –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω header, –∑–∞–ø–∏—Å–∞—Ç—å –µ–≥–æ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–æ–π.
    –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ –∫–∞–∂–¥–∞—è —Å—Ç—Ä–æ–∫–∞ –≤ rows –∏–º–µ–µ—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—É—é –¥–ª–∏–Ω—É (–∏–Ω–∞—á–µ ValueError)."""
    p = Path(path)
    rows = list(rows)
    if not rows:
        return 
    
    length = len(rows[0])
    for i in rows:
        if len(i)!= length:
            raise ValueError('–í—Å–µ —Å—Ç—Ä–æ–∫–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤–æ–π –¥–ª–∏–Ω—ã')
            
    with p.open('w', newline='', encoding='utf-8') as f: # –∫–æ—Ä–µ–∫—Ç–∏—Ä—É–µ—Ç –ø–µ—Ä–µ–Ω–æ—Å —Å—Ç—Ä–æ–∫ –≤ csv
        writer = csv.writer(f, delimiter=',', quoting=csv.QUOTE_MINIMAL) # —É–ø—Ä–∞–ª–µ–Ω–∏–µ –∫–∞–≤—ã—á–∫–∞–º–∏, —Å—Ç–∞–≤–∏—Ç —Ç–æ–ª—å–∫–æ –∫–æ–≥–¥–∞ –Ω–∞–¥–æ
        if header:
            writer.writerow(header)
        writer.writerows(rows)


text_2 = write_csv([("word","count"),("test",3)], r'python_labs/data/checkcsv')
print(text_2) 
 ```
 ## –ó–∞–¥–∞–Ω–∏–µ B
 ```python
 import sys, os, csv
from pathlib import Path 
import argparse
sys.path.append(os.path.dirname(os.path.dirname(__file__)))
from func_from_3lab import normalize, tokenize, count_freq, top_n

def main():
    parser = argparse.ArgumentParser(description='Word freq report')#—Å–æ–∑–¥–∞—ë–º –æ–±—ä–µ–∫—Ç –ø–∞—Ä—Å–µ—Ä–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤. 
    parser.add_argument('--in', dest='input_file', default='data/input.txt')
    parser.add_argument('--out', dest='output_file', default='data/output.txt')
    parser.add_argument('--encoding', default='utf-8')
    args = parser.parse_args()

    try:
        with open(args.input_file, 'r', encoding=args.encoding) as f:
            text = f.read()
    except FileNotFoundError:
        raise FileNotFoundError('–ù–µ—Ç —Ç–∞–∫–æ–≥–æ —Ñ–∞–π–ª–∞')
    except UnicodeDecodeError:
        raise UnicodeDecodeError('–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –∫–æ–¥–∏—Ä–æ–≤–∫–∞')
    
    normalized_text = normalize(text)
    words = tokenize(normalized_text)
    freq = count_freq(words)

    total_words = len(words)
    unique_words = len(freq)

    sorted_words = sorted(freq.items(), key=lambda x: (-x[1], x[0]))

    os.makedirs(os.path.dirname(args.output_file), exist_ok=True)
    with open(args.output_file, 'w', encoding='utf-8') as f:
        f.write("word,count\n")
        for word, count in sorted_words:
            f.write(f"{word},{count}\n")
    
    print(f'–í—Å–µ–≥–æ —Å–ª–æ–≤: {total_words}')
    print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {unique_words}")
    print("–¢–æ–ø-5:")
    for word, count in sorted_words[:5]:
        print(f"{word}: {count}")

if __name__ == '__main__':
    main()
 ```
## –¢–µ—Å—Ç-–∫–µ–π—Å—ã:
### –∑–∞–ø—É—Å–∫ —Å –æ–±—ã—á–Ω—ã–º —Ñ–∞–π–ª–æ–º

![–†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–¥–∞–Ω–∏—è 1](/images/image-23.png)

![–†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–¥–∞–Ω–∏—è 2](/images/image-24.png)

![–†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–¥–∞–Ω–∏—è 3](/images/image-25.png)

### –∑–∞–ø—É—Å–∫ —Å –ø—É—Å—Ç—ã–º —Ñ–∞–π–ª–æ–º

![–†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–¥–∞–Ω–∏—è 1](/images/image-26.png)

![–†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–¥–∞–Ω–∏—è 2](/images/image-27.png)

![–†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–¥–∞–Ω–∏—è 3](/images/image-28.png)

### –∑–∞–ø—É—Å–∫ –∫–æ–≥–¥–∞ —Ñ–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
![–†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–¥–∞–Ω–∏—è 1](/images/image-29.png)

# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ ‚Ññ5
## –ó–∞–¥–∞–Ω–∏–µ A 
### (JSON -> CSV)

```python
import json 
import csv
import sys
from pathlib import Path
def json_to_csv(json_path: str, csv_path:str) -> None:
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –ø—É—Ç–∏ –≤ Path –æ–±—ä–µ–∫—Ç—ã –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏—Ö
    input_path = Path(json_path).expanduser().resolve()
    output_path = Path(csv_path).expanduser().resolve()
    if not input_path.exists():
        raise FileNotFoundError(f"JSON file –Ω–µ –Ω–∞–π–¥–µ–Ω: {json_path}")
    if input_path.stat().st_size == 0:
        raise ValueError("JSON —Ñ–∞–π–ª –ø—É—Å—Ç–æ–π")
    
    with open(input_path, encoding='utf-8') as json_file:
        try:
            data = json.load(json_file)
        except json.JSONDecodeError:
            raise ValueError("–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –∫–æ–¥–∏—Ä–æ–≤–∫–∞")
    if not all(isinstance(item, dict) for item in data):
        raise ValueError("–í—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã JSON –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä—è–º–∏")
    
    all_keys = set()
    for item in data:
        all_keys.update(item.keys())
    
    fieldnames = sorted(all_keys)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, 'w', newline='', encoding='utf-8') as csv_file:
        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)
        writer.writeheader()
        for item in data:
            row = {}
            for field in fieldnames:
                value = item.get(field)
                row[field] = str(value) if value is not None else ""
            writer.writerow(row)
if __name__ == "__main__":
    json_to_csv("data_lab_05\people.json", "data_lab_05\people_from_json.csv")
```
## –¢–µ—Å—Ç-–∫–µ–π—Å—ã:
### –∑–∞–ø—É—Å–∫ —Å –æ–±—ã—á–Ω—ã–º —Ñ–∞–π–ª–æ–º
![–ò—Å—Ö–æ–¥–Ω—ã–π JSON](/images/image-30.png)
![–†–µ–∑—É–ª—å—Ç–∞—Ç –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –∏–∑ JSON –≤ CSV](/images/image-31.png)

### –∑–∞–ø—É—Å–∫ —Å –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º —Ñ–∞–π–ª–æ–º
![–†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–ø—É—Å–∫–∞](/images/image-32.png)

### –∑–∞–ø—É—Å–∫ —Å –ø—É—Å—Ç—ã–º —Ñ–∞–π–ª–æ–º
![–†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–ø—É—Å–∫–∞](/images/image-33.png)


### (CSV -> JSON)
```python
import json 
import csv
import sys
from pathlib import Path
def csv_to_json(csv_path: str, json_path: str) -> None:
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –ø—É—Ç–∏ –≤ Path –æ–±—ä–µ–∫—Ç—ã –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏—Ö
    input_file = Path(csv_path).expanduser().resolve()
    output_file = Path(json_path).expanduser().resolve()

    if not input_file.exists():
        raise FileNotFoundError('–§–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç')
    if not csv_path.lower().endswith('.csv'):
        raise ValueError('–ù–µ–∫–æ—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞')
    
    data = []
    try:
        with open(input_file, 'r', encoding='utf-8') as csv_file:
            csv_reader = csv.DictReader(csv_file)
            for row in csv_reader:
                data.append(row)
    except UnicodeDecodeError:
        raise UnicodeDecodeError('–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è –∫–æ–¥–∏—Ä–æ–≤–∫–∞ —Ñ–∞–π–ª–∞')
    output_file.parent.mkdir(parents=True, exist_ok=True)
    with open(output_file, 'w', encoding='utf-8') as json_file:
        json.dump(data, json_file, ensure_ascii=False, indent=2)
if __name__ == "__main__":
    csv_to_json(r'python_labs\data_lab_05\people.csv', r'python_labs\data_lab_05\people_from_csv.json')
```
## –¢–µ—Å—Ç-–∫–µ–π—Å—ã:
### –∑–∞–ø—É—Å–∫ —Å –æ–±—ã—á–Ω—ã–º —Ñ–∞–π–ª–æ–º
![–ò—Å—Ö–æ–¥–Ω—ã–π JSON](/images/image-34.png)
![–†–µ–∑—É–ª—å—Ç–∞—Ç –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –∏–∑ CSV –≤ JSON](/images/image-35.png)

### –∑–∞–ø—É—Å–∫ —Å –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º —Ñ–∞–π–ª–æ–º
![–†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–ø—É—Å–∫–∞](/images/image-36.png)

### –∑–∞–ø—É—Å–∫ —Å –ø—É—Å—Ç—ã–º —Ñ–∞–π–ª–æ–º
![–†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–ø—É—Å–∫–∞](/images/image-37.png)

## –ó–∞–¥–∞–Ω–∏–µ B (CSV ‚Üí XLSX)
```python
import csv
from pathlib import Path
from openpyxl import Workbook

def csv_xlsx(csv_path: str, xlsx_path: str) -> None:
    current_file = Path(__file__)
    project_root = current_file.parent.parent.parent

    input_file = project_root / csv_path
    output_file = project_root / xlsx_path

    if not input_file.exists():
        raise FileNotFoundError('–§–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç')
    if not csv_path.lower().endswith('.csv'):
        raise ValueError('–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞')

    output_file.parent.mkdir(parents=True, exist_ok=True)

    wb = Workbook()
    ws = wb.active
    ws.title = "Sheet1"
    try:
        with open(input_file, 'r', encoding="utf-8") as csv_file:
            csv_reader = csv.reader(csv_file)
            for row in csv_reader:
                ws.append(row)
    except UnicodeEncodeError:
        raise UnicodeEncodeError('–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è –∫–æ–¥–∏—Ä–æ–≤–∫–∞ —Ñ–∞–π–ª–∞')
    wb.save(output_file)
```

## –∑–∞–ø—É—Å–∫ —Å –æ–±—ã—á–Ω—ã–º —Ñ–∞–π–ª–æ–º

![–ò—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª CSV](/images/image-38.png)
![–†–µ–∑—É–ª—å—Ç–∞—Ç –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –∏–∑ CSV –≤ XLSX](/images/image-39.png)


# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ ‚Ññ6
## –ó–∞–¥–∞–Ω–∏–µ A - cli_convert
```python
import argparse
import sys, os
from pathlib import Path
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

from lab05.csv_json import csv_to_json
from lab05.csv_xls import csv_xlsx
from lab05.json_csv import json_to_csv

def main():
    parser = argparse.ArgumentParser(description='–ö–æ–Ω–≤–µ—Ä—Ç—ã –¥–∞–Ω–Ω—ã—Ö')
    subparsers = parser.add_subparsers(dest='command')

    json_csv_parser = subparsers.add_parser('json2csv', help='–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –∏–∑ json –≤ csv')
    json_csv_parser.add_argument('--input', required=True, help='–í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª')
    json_csv_parser.add_argument('--output', required=True, help='–í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª')

    csv_json_parser = subparsers.add_parser('csv2json', help='–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –∏–∑ csv –≤ json')
    csv_json_parser.add_argument('--input', required=True, help='–í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª')
    csv_json_parser.add_argument('--output', required=True, help='–í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª')

    csv_xlsx_parser = subparsers.add_parser('csv2xlsx', help='–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –∏–∑ csv –≤ xlsx')
    csv_xlsx_parser.add_argument('--input', required=True, help='–í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª')
    csv_xlsx_parser.add_argument('--output', required=True, help='–í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª')

    args = parser.parse_args()
    if args.command is None:
        parser.print_help()
        sys.exit(1)

    input_file = Path(args.input).expanduser()
    if not input_file.is_absolute():
        input_file = (Path.cwd() / input_file).resolve()
    else:
        input_file = input_file.resolve()

    output_file = Path(args.output).expanduser()
    if not output_file.is_absolute():
        output_file = (Path.cwd() / output_file).resolve()
    else:
        output_file = output_file.resolve()

    if not input_file.exists():
        print(f"–û—à–∏–±–∫–∞: –≤—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {input_file}")
        sys.exit(1)

    if args.command == 'json2csv':
        json_to_csv(str(input_file), str(output_file))
    elif args.command == 'csv2json':
        csv_to_json(str(input_file), str(output_file))
    elif args.command == 'csv2xlsx':
        csv_xlsx(str(input_file), str(output_file))
            
if __name__ == "__main__":
    main()
```
## —Å–≤–æ–¥–∫–∞ -h –∫–æ–º–∞–Ω–¥
### python src/lab06/cli_convert.py json2csv -h
### python src/lab06/cli_convert.py csv2json -h
### python src/lab06/cli_convert.py csv2xlsx -h

## —Å–≤–æ–¥–∫–∞ –∫–æ–º–∞–Ω–¥ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
### python src/lab06/cli_convert.py json2csv --input src\lab06\data\people.json --output src\lab06\data\people.csv
### python src/lab06/cli_convert.py csv2json --input src\lab06\data\people.csv --output src\lab06\data\people.json
### python src/lab06/cli_convert.py csv2xlsx --input src\lab06\data\people.csv --output src\lab06\data\people.xlsx

## –ó–∞–¥–∞–Ω–∏–µ B - cli_text

```python
import argparse
import sys, os
from pathlib import Path
sys.path.append(os.path.dirname(os.path.dirname(__file__)))
from lab03.text import tokenize, count_freq, top_n

def num_str(input_path, number_lines=False): 
    try:
        with open(input_path, 'r', encoding='utf-8') as f:
            line_num = 1
            for line in f:
                if number_lines:
                    print(f"{line_num}: {line}", end='')
                    line_num+=1
                else:
                    print(line, end='')
    except FileNotFoundError:
        print('–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω')
        sys.exit(1)

def stat_text(input_path: Path, top=5):
    try:
        with open(input_path, 'r', encoding='utf-8') as f:
            text = f.read()
    except FileNotFoundError:
        print("–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω:", input_path)
        sys.exit(1)

    tokens = tokenize(text)
    freq = count_freq(tokens)
    top_words = top_n(freq, top)

    print(f"–í—Å–µ–≥–æ —Å–ª–æ–≤: {len(tokens)}")
    print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {len(set(tokens))}")
    print("–¢–æ–ø —Å–ª–æ–≤:")

    for word, count in top_words:
        print(f"{word}: {count}")

def main():
    parser = argparse.ArgumentParser(description="CLI‚Äë—É—Ç–∏–ª–∏—Ç—ã –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–æ–π ‚Ññ6")
    subparsers = parser.add_subparsers(dest="command")

    # –ø–æ–¥–∫–æ–º–∞–Ω–¥–∞ cat
    cat_parser = subparsers.add_parser("cat", help="–í—ã–≤–æ–¥–∏—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞")
    cat_parser.add_argument('--input', required=True, help='–ü—É—Ç—å –∫ —Ç–µ–∫—É—â–µ–º—É —Ñ–∞–π–ª—É')
    cat_parser.add_argument('-n', action="store_true", help='–ù—É–º–µ—Ä—É–µ—Ç —Å—Ç—Ä–æ–∫–∏')

    # –ø–æ–¥–∫–æ–º–∞–Ω–¥–∞ stats
    stats_parser = subparsers.add_parser("stats", help="–ß–∞—Å—Ç–æ—Ç—ã —Å–ª–æ–≤")
    stats_parser.add_argument('--input', required=True, help='–ü—É—Ç—å –∫ —Ç–µ–∫—É—â–µ–º—É —Ñ–∞–π–ª—É')
    stats_parser.add_argument('--top', type=int, default=5, help='—Å–∫–æ–ª—å–∫–æ –≤ —Ç–æ–ø–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Å–ª–æ–≤, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 5')

    args = parser.parse_args()

    if args.command == 'cat':
        input_path = Path(args.input)
        num_str(input_path, number_lines=args.n)
    elif args.command == 'stats':
        input_path = Path(args.input, top=args.top)
        stat_text(input_path)

if __name__ == "__main__":
    main()
```
## —Å–≤–æ–¥–∫–∞ -h –∫–æ–º–∞–Ω–¥
### python src/lab06/cli_text.py cat --input src\lab06\data\test.txt -h
### python src/lab06/cli_text.py stats --input src\lab06\data\test.txt -h
## —Å–≤–æ–¥–∫–∞ –∫–æ–º–∞–Ω–¥
#### –ø—Ä–æ—Å—Ç–æ –≤—ã–≤–æ–¥–∏—Ç —Ç–µ–∫—Å—Ç 
### python src/lab06/cli_text.py stats --input src\lab06\data\test.txt
#### –≤—ã–≤–æ–¥–∏—Ç —Ç–µ–∫—Å—Ç —Å –Ω—É–º–µ—Ä–∞—Ü–∏–µ–º
### python src/lab06/cli_text.py cat --input src\lab06\data\test.txt -n
## –†–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞–±–æ—Ç—ã:
### –ø–æ–¥—Å–∫–∞–∑–∫–∏
![–ø–æ–¥—Å–∫–∞–∑–∫–∏](/images/image-40.png)
![–ø–æ–¥—Å–∫–∞–∑–∫–∏](/images/image-41.png)
### –æ–±—ã—á–Ω–∞—è —Ä–∞–±–æ—Ç–∞
![—Ä–µ–∑—É–ª—å—Ç–∞—Ç](/images/image-42.png)
![—Ä–µ–∑—É–ª—å—Ç–∞—Ç](/images/image-43.png)
![—Ä–µ–∑—É–ª—å—Ç–∞—Ç](/images/image-44.png)


# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ ‚Ññ7
## –ó–∞–¥–∞–Ω–∏–µ 1 (–∞–≤—Ç–æ—Ç–µ—Å—Ç—ã –¥–ª—è –≤—Å–µ—Ö —Ñ—É–Ω–∫—Ü–∏–π –º–æ–¥—É–ª—è)
```python
import pytest
import sys, os
from pathlib import Path

sys.path.append(os.path.dirname(os.path.dirname(__file__)))
from src.lib.text import normalize, tokenize, count_freq, top_n


@pytest.mark.parametrize(
    "in_data, expected",
    [
        ("–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t", "–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"),
        ("—ë–∂–∏–∫, –Å–ª–∫–∞", "–µ–∂–∏–∫ –µ–ª–∫–∞"),
        ("Hello\r\nWorld", "hello world"),
        ("  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  ", "–¥–≤–æ–π–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã"),
        ("", ""),
        ("       ", ""),
        ("123  456", "123 456"),
        ("–ú–Ω–æ–≥–æ\t\t\t—Ç–∞–±–æ–≤", "–º–Ω–æ–≥–æ —Ç–∞–±–æ–≤"),
    ],
)
def test_normalize(in_data, expected):
    assert normalize(in_data) == expected


@pytest.mark.parametrize(
    "text, expected",
    [
        ("–ø—Ä–∏–≤–µ—Ç –º–∏—Ä", ["–ø—Ä–∏–≤–µ—Ç", "–º–∏—Ä"]),
        ("hello,world!!!", ["hello", "world"]),
        ("–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ", ["–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É", "–∫—Ä—É—Ç–æ"]),
        ("2025 –≥–æ–¥", ["2025", "–≥–æ–¥"]),
        ("emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ", ["emoji", "–Ω–µ", "—Å–ª–æ–≤–æ"]),
        ("", []),
        ("    ", []),
        ("!!!", []),
        ("a-b-c", ["a-b-c"]),
        ("–∫–∏—Ä–∏–ª–ª–∏—Ü–∞ and english", ["–∫–∏—Ä–∏–ª–ª–∏—Ü–∞", "and", "english"]),
    ],
)
def test_tokenize_basic(text, expected):
    assert tokenize(text) == expected


@pytest.mark.parametrize(
    "tokens, expected",
    [
        (["a", "b", "a", "c", "b", "a"], {"a": 3, "b": 2, "c": 1}),
        ([], {}),
        (["word"], {"word": 1}),
        (["word", "Word", "WORD"], {"word": 1, "Word": 1, "WORD": 1}),
        (["word", "word", "word"], {"word": 3}),
    ],
)
def test_count_freq(tokens, expected):
    assert count_freq(tokens) == expected


@pytest.mark.parametrize(
    "freq_dict, n, expected",
    [
        ({"a": 3, "b": 2, "c": 1}, 2, [("a", 3), ("b", 2)]),
        ({}, 1, []),
        ({"c": 3, "b": 3, "v": 3}, 3, [("b", 3), ("c", 3), ("v", 3)]),
        ({"a": 1, "b": 1}, 5, [("a", 1), ("b", 1)]),
        ({"a": 3, "b": 3, "c": 2}, 2, [("a", 3), ("b", 3)]),
    ],
)
def test_top_n(freq_dict, n, expected):
    assert top_n(freq_dict, n) == expected
```


## –ó–∞–¥–∞–Ω–∏–µ 2 (–∞–≤—Ç–æ—Ç–µ—Å—Ç—ã –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–π –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–π —Ñ–∞–π–ª–æ–≤)
```python
import pytest
import sys, os
import csv
import json
from pathlib import Path
sys.path.append(os.path.dirname(os.path.dirname(__file__)))
from src.lib.csv_json import csv_to_json
from src.lib.json_csv import json_to_csv

def test_json_to_csv_base(tmp_path: Path): 
    src = tmp_path / "people.json" # –≥–æ—Ç–æ–≤–∞—è –≤—Ä–µ–º–µ–Ω–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è (—Ñ–∏–∫—Å—Ç—É—Ä–∞ pytest)
    dst = tmp_path / "people.csv"
    data = [
        {"name": "Alice", "age": 22},
        {"name": "Bob", "age": 25},
    ]
    src.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")
    json_to_csv(str(src), str(dst))

    with dst.open(encoding="utf-8") as f:
        rows = list(csv.DictReader(f))

    assert len(rows) == 2
    assert {"name", "age"} <= set(rows[0].keys())

def test_json_to_csv_file_not_found(): # –∫–æ–≥–¥–∞ –Ω–µ—Ç —Ñ–∞–π–ª–∞
     with pytest.raises(FileNotFoundError, match="JSON file –Ω–µ –Ω–∞–π–¥–µ–Ω"):
          json_to_csv("not_ex_file.json", "output.csv")


def test_json_to_csv_file_is_empty(tmp_path): # –∫–æ–≥–¥–∞ —Ñ–∞–π–ª –ø—É—Å—Ç–æ–π
    src = tmp_path / 'empty_file.json'
    dst = tmp_path / "output.csv"

    src.write_text('')
    with pytest.raises(ValueError, match="JSON —Ñ–∞–π–ª –ø—É—Å—Ç–æ–π"):
        json_to_csv(str(src), str(dst))
    

def test_json_to_csv_not_a_dict(tmp_path): # –∫–æ–≥–¥–∞ –Ω–µ –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã —Å–ª–æ–≤–∞—Ä–∏
    src = tmp_path / 'invalid.json'
    dst = tmp_path / "output.csv"

    data = '–Ω–µ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π'
    src.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")
    with pytest.raises(ValueError, match="–í—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã JSON –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä—è–º–∏"):
        json_to_csv(str(src), str(dst))


def test_json_to_csv_special_characters(tmp_path):
    src = tmp_path / 'input.json'
    dst = tmp_path / "output.csv"

    data = [
        {"name": "–•–æ–∞–Ω–≥", "age": "18"},
        {"name": "Ho√†ng", "age": "19"},
    ]
    
    src.write_text(json.dumps(data, ensure_ascii= False, indent=2), encoding='utf-8')
    json_to_csv(str(src), str(dst))

    assert dst.exists()

    with open(dst, 'r', encoding='utf-8') as f:
        content = f.read()
    assert "Ho√†ng" in content
    assert '–•–æ–∞–Ω–≥' in content

def test_json_to_csv_none_values(tmp_path):
    src = tmp_path / "none.json"
    dst = tmp_path / "output.csv"

    data = [
        {"name": "ALice", "age": None, "city": None},
        {"name": "Bob", "age": '18', "city": None},
    ]
    src.write_text(json.dumps(data, ensure_ascii= False, indent= 2), encoding= 'utf-8')
    json_to_csv(str(src), str(dst))
    
    with open(dst, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        rows = list(reader)
    
    assert rows[0]['age'] == ''
    assert rows[1]['city'] == ''
    


def test_csv_to_json_roundtrip(tmp_path: Path):
    src = tmp_path / "people.csv"
    dst = tmp_path / "people.json"

    with open(src, 'w', encoding='utf-8', newline='') as f:
        writer = csv.DictWriter(f, fieldnames=["name", "age"])
        writer.writeheader()
        writer.writerow({"name": "Alice", "age": "22"})
        writer.writerow({"name": "Bob", "age": "25"})

    csv_to_json(str(src), str(dst))
    assert dst.exists()
    with open(dst, 'r', encoding='utf-8') as f:
            data = json.load(f)
    assert len(data) == 2
    assert data[0]["name"] == "Alice"
    assert data[1]["name"] == "Bob"
    assert data[0]["age"] == "22"
    assert data[1]["age"] == "25"


def test_csv_to_json_file_not_found():
    with pytest.raises(FileNotFoundError, match='–§–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç'):
        csv_to_json("not_ex_file.csv", "output.json")

def test_csv_to_json_not_right_format(tmp_path: Path):
    src = tmp_path / "file.txt"  
    dst = tmp_path / "output.json"
    
    src.write_text("some content", encoding='utf-8')
    
    with pytest.raises(ValueError, match="–ù–µ–∫–æ—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞"):
        csv_to_json(str(src), str(dst))
    


def test_csv_to_json_empty_cells(tmp_path: Path):
        src = tmp_path / "empty.csv"
        dst = tmp_path / "output.json"
        with open(src, 'w', encoding='utf-8', newline='') as f:
            writer = csv.DictWriter(f, fieldnames=["name", "age", "city"])
            writer.writeheader()
            writer.writerow({"name": "Alice", "age": "22", "city": "Moscow"})
            writer.writerow({"name": "Bob", "age": "", "city": "SPb"})                
            writer.writerow({"name": "Charlie", "age": "30", "city": ""})
        csv_to_json(str(src), str(dst))
        
        with open(dst, 'r', encoding='utf-8') as f:
            data = json.load(f)
            
        assert len(data) == 3
        assert data[1]["age"] == ""  
        assert data[2]["city"] == ""  



def test_csv_to_json_different_colums(tmp_path: Path):
    src = tmp_path / 'input.csv'
    dst = tmp_path / 'output.json'

    with open(src, 'w', encoding='utf-8', newline='') as f:
        f.write('name,age,city\n')
        f.write("Alice,22,Moscow\n")
        f.write("Bob,25,\n")  # –ü—É—Å—Ç–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è city
        f.write("Charlie,,SPb\n")  # –ü—É—Å—Ç–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è age

    csv_to_json(str(src), str(dst))

    with open(dst, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    assert len(data) == 3
    assert data[1]['city'] == ''  # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∑–Ω–∞—á–µ–Ω–∏–µ –ø—É—Å—Ç–æ–µ
    assert data[2]['age'] == ''   # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ age –ø—É—Å—Ç–æ–µ

```

### –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤ –≤ CLI —Å –ø–æ–∫—Ä—ã—Ç–∏–µ–º
![—Ä–µ–∑—É–ª—å—Ç–∞—Ç](/images/image-45.png)
